# Practice: Open Source LLMs

This repository is a structured log of my experiments with local Large Language Models. 

I started this because I wanted to move beyond just calling APIs. I wanted to understand how to actually run, optimize, and interface with models on my own hardware. This is where I break things, fix them, and document the process.

## ðŸ›  Project Structure

*   `/notebooks`: Step-by-step experiments with inference and RAG.
*   `/scripts`: Python utilities for model loading and data processing.
*   `/configs`: Environment setups and model parameters.

## ðŸ§ª Current Focus
*   **Local Inference:** Running Llama 3 and Mistral using `transformers` and `Ollama`.
*   **Quantization:** Testing the performance trade-offs of 4-bit and 8-bit models.
*   **RAG:** Building simple retrieval pipelines to chat with local documents.

## ðŸš€ Getting Started

1. **Clone the repo:**
   ```bash
   git clone https://github.com/shreyaskr422/pratice-open-source-LLM.git
